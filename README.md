# DSR: Dialectical Structured Reasoning for Explainable Multimodal Fake News Detection

This repository contains the official PyTorch implementation of the paper **"Dialectical Structured Reasoning for Explainable Multimodal Fake News Detection"**.

DGR is a multi-agent framework that employs a **Fake Agent** (Debunker) and a **Real Agent** (Verifier) to retrieve conflicting evidence paths from social propagation graphs. A **Judge Agent**, powered by a Large Language Model (LLM), then performs dialectical reasoning to determine the veracity of the news, integrating multimodal evidence and internal knowledge.


## ğŸ› ï¸ Requirements

*   Python >= 3.10
*   PyTorch >= 2.0 (with CUDA support)
*   Transformers
*   Accelerate
*   PEFT & BitsAndBytes (for 4-bit LoRA fine-tuning)

Install dependencies via:
```bash
pip install -r requirements.txt
```

## ğŸ“‚ Data Preparation

### 1. Raw Datasets
Please download the raw datasets from their respective sources and place them in `data/raw`:
*   **FakeNewsNet** (PolitiFact & GossipCop)
*   **Fakeddit**

### 2. Preprocessing & Unification
Convert raw data into the unified JSON format:
```bash
python src/dataprocessing/clean_fakenewsnet.py
python src/dataprocessing/clean_fakeddit.py
```

### 3. Evidence Generation 
Enhance the dataset with LLM-generated background knowledge and logical evidence paths :
```bash
# Generate background knowledge and evidence paths
python src/agents/offline_reasoning.py
```

## ğŸš€ Training

We employ a **specialist training strategy**, training separate models for each domain (PolitiFact, GossipCop, Fakeddit) to maximize performance.

To start training (sequentially):
```bash
bash scripts/run_train.sh
```

You can configure hyperparameters in `src/train.py` or `scripts/run_train.sh`.
*   **Default Epochs**: 50 (with Early Stopping)
*   **Batch Size**: 1 (Gradient Accumulation = 16)
*   **Optimization**: LoRA (Low-Rank Adaptation) for the Judge Agent (Qwen2.5-7B).

## ğŸ“Š Evaluation

To evaluate the best checkpoint on the held-out test set:

```bash
python src/eval_.py
```
*Note: Ensure you update `BEST_MODEL_PATH` in `src/eval_.py` to point to your target checkpoint.*

## ğŸ” Interpretability & Analysis

To generate a detailed reasoning report for a specific news sample:

```bash
python src/explain_one.py
```
This script will output:
1.  **Attention Weights**: The importance score of Fake vs. Real evidence paths.
2.  **Evidence Content**: The actual social media comments or image descriptions used.
3.  **AI Reasoning**: A natural language explanation generated by the Judge Agent.

## ğŸ“ Project Structure

```text
DSR/
â”œâ”€â”€ data/                   
â”œâ”€â”€ pretrained_models/     
â”œâ”€â”€ checkpoints/           
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_train.sh       
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/             
â”‚   â”œâ”€â”€ dataprocessing/    
â”‚   â”œâ”€â”€ models/             
â”‚   â”œâ”€â”€ dataset_loader.py   
â”‚   â”œâ”€â”€ train.py           
â”‚   â”œâ”€â”€ eval_.py           
â”‚   â””â”€â”€ explain_one.py      
â”œâ”€â”€ config.py               
â””â”€â”€ requirements.txt
```
